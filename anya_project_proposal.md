# Ethics of the Datasets of {Name of the Model}

## Abstract & Objectives
This project aims to delve into the datasets supporting {name of the model} and explore avenues for enhancing the library's documentation. The research involves examination of the datasets currently employed by ml5.js for {name of the model}, alongside an investigation into datasets commonly utilized by other models, particularly those based on TensorFlow.js.

The project's primary objectives include evaluating the diversity and potential biases within the existing datasets and proposing improvements to boost model performance across various scenarios. By comparing datasets and understanding their impact on model outcomes, the project seeks to contribute valuable insights to the ml5.js community.

The project also proposes the creation of a dedicated webpage or integration with an existing one within the ml5.js documentation. This page will serve as an informative resource on the datasets associated with different {name of the model/category of the model}. It will employ accessible language, visual aids, and practical tips to guide users through the nuances of dataset selection and its influence on model performance. Additionally (in collaboration with the Website crew) make Model & Data Provenance page more readable (e.g. make it into a table).

The reasons for this project is not only to foster transparency, inclusivity and user-friendly documentation of the library, but also to be intentional about informing the users of the possible bias or innaccuracies as well as possible reasons behind them.


## References
- TensorFlow.js datasets
    - https://www.tensorflow.org/datasets
- ImageNet 
    - https://image-net.org/challenges/LSVRC/index.php
- All the Ml5.js Model & Data Provenance info
- Research papers that explore the accuracy of different models & respecive datasets. A bunch of them are already included in TensorFlow.js own documentation

## Methodology
1. Identify which model/models I am going to be working with. The criteria: lack of description regarding their accuracy + certainty regarding the invovled datasets
2. Look into recent cases regarding  
3. Look into the datasets that are in use currently for that model
4. See if there are any alternatives
5. Look into similar projects to Ml5.js and see how they deal with informing their users of the possible inaccuracies
6. Create materials that outline areas for improvement & inform the users 
7. TBD

## Challenges
Possible challenges include:
- Lack of research of the inclusivity of the datasets 
- Uncertain legal ground (what is considered sufficient when it comes to informing the users)
- As it will be my first time diving into reading research regarding how different datasets are assembled & used on the back-end, I might find it difficult to deal with the language and the technical aspects.

## Final Deliverable

Final outcome will most likely be a combination of suggestions regarding the choice of datasets as well as documentation that informs the user of the potential inaccuracies. 

## Timeline

- Jan 31 - Feb 14: Conduct preliminary research and gather resources. Finalize project plan and post to class GitHub.
- Feb 14 - Feb 28: Identify the model(s) that I am going to be working with. Start looking into existing research about the involved datasets. 
- Feb 28 - Mar 13: Compare my findings with the existing documentation. Look into how similar peojects approach that on their websites/apps. Possibly collaborate with the website team to see what they are planning to change.
- Mar 13 - Mar 27: Potentially assemble an improved documentation. Maybe even suggest an alternative way to inform the users. 
- Mar 27 - Apr 10: Potentially assemble an improved documentation. Maybe even suggest an alternative way to inform the users.
- Apr 10 - Apr 17: Prepare final presentation.
